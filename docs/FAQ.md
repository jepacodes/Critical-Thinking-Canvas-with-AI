# Frequently Asked Questions

Real questions, honest answers.

---

## General Questions

### Isn't this just extra work?

Yes and no.

Yes, it takes longer to engage deeply than to let AI do the work. There's no getting around that.

But here's the thing: for work that matters, the thinking *is* the work. If you're doing knowledge work, your value comes from your judgment, your expertise, your ability to understand complex situations. When you outsource that to AI, you're outsourcing the valuable part.

The extra time isn't wasted—it's where the actual value is created.

For work that doesn't matter, don't use this framework. Let AI handle it. Save your deep engagement for things that are worth it.

---

### When should I NOT use this framework?

When there's no thinking to protect.

- Pure execution tasks (formatting, converting, generating boilerplate)
- Things outside your development area that you'll never need to understand deeply
- Low-stakes decisions where overthinking is itself a problem
- Urgent tasks where speed genuinely matters more than depth

The framework is for tasks where developing or exercising your judgment is part of the point. For everything else, just use AI.

---

### What if I disagree with part of the framework?

Good. You should be skeptical.

This framework is based on Advait Sarkar's research, but it's not doctrine. If part of it doesn't match your experience, trust your experience.

The core insight—that outsourcing thinking can erode thinking capacity—is well-supported by research. But how you apply that insight should fit your situation.

Adapt the framework. Skip what doesn't help. Add what's missing. The goal is to make you think better, not to follow rules.

---

### How do I know if I'm doing this right?

A few signals:

**You can defend your work.** If someone challenged you, you could explain your reasoning without looking at notes.

**You learned something.** The process made you understand something you didn't before.

**You could recreate it.** If AI disappeared, you could produce something similar (maybe slower, but similar).

**You made real decisions.** There were moments where you chose between alternatives, not just accepted what AI suggested.

If these are true, you're doing it right—regardless of how closely you followed the workbook.

---

### Can I use this for creative work?

Yes, but the application is different.

For creative work, "material engagement" might mean engaging with your own ideas before asking AI for help. Form your own creative direction first, then use AI to explore variations or overcome blocks.

"Productive resistance" might mean using AI to challenge your creative choices—why this approach instead of that one? What would a different aesthetic look like?

The danger in creative work is AI flattening your voice into something generic. The framework helps you stay in control of the creative direction while using AI as a tool.

---

## Using the Workbook

### Do I need to use all six canvases?

No. Use what helps.

For most tasks, the **AI Decision Canvas** (the Three Questions) is enough. Run through it quickly before starting.

Use the other canvases when you need more structure:
- **Task Analysis** when you need clarity about what you're doing
- **Strategic Engagement** when mapping a complex task
- **Thought Architecture** for projects that need external thinking structures
- **Authenticity Review** before finalizing important work
- **Implementation Tracker** once, to build the habit

---

### Can I skip questions that don't apply?

Yes. The goal is to think through what matters, not to fill in every box.

If a question doesn't apply to your task, skip it. The canvases are prompts for thinking, not compliance checklists.

---

### How long does this take?

For the AI Decision Canvas: 5-10 minutes once you're familiar with it. Maybe 2 minutes once it's instinctive.

For the full canvas set on a complex task: 30-60 minutes upfront. But this is planning time that often saves time later.

The Implementation Tracker is designed for 3 weeks of practice, but that's building a habit, not daily overhead.

---

### What if I can't check all the boxes honestly?

That's useful information. It means your planned approach would bypass important thinking.

You have options:

1. **Redesign your approach.** Find a way to maintain engagement while still using AI.

2. **Proceed anyway, knowingly.** Sometimes speed matters more than depth. Just be aware of the trade-off.

3. **Don't use AI for this part.** Some tasks are better done without AI assistance.

The framework isn't about perfection. It's about conscious choice. If you can't check the boxes but proceed anyway, at least you know what you're trading off.

---

## Specific Situations

### What about tasks where I genuinely don't have expertise?

The framework has guidance for this—it's the "Outside My Domain" section in the Task Analysis Canvas.

The key points:
- Use AI to learn, not to shortcut learning
- Verify everything carefully (you can't spot AI errors in unfamiliar domains)
- Engage more heavily with source materials
- Consider getting human expert validation for important things

When you're learning, the struggle of understanding is exactly what you need. Don't skip it.

---

### What about collaboration with others who use AI differently?

This is tricky. You can't control how others use AI.

What you can do:
- Be transparent about your own approach
- When reviewing AI-generated work from others, probe for understanding ("Can you walk me through why this recommendation?")
- For important decisions, ensure someone has actually engaged with the thinking, not just the output

Sometimes you'll need to accept that others are doing things differently. Focus on what you can control.

---

### What if my job requires me to use AI in ways that bypass thinking?

This is a real tension.

If your organization measures output and speed rather than quality of thinking, you're in a bind. The framework assumes you have some control over how you work.

Some options:
- Use the framework for your own important work, even if not for everything
- Advocate for the value of deeper engagement
- Be strategic about where you invest thinking vs. where you let AI handle it

If your job is literally to review and publish AI output with minimal modification, this framework may not fit. But that's also a job where your long-term value proposition is eroding.

---

### What about using AI for things I find genuinely tedious?

That's often fine—if the tedious part isn't where the thinking lives.

Formatting: let AI handle it.  
Boilerplate writing: let AI draft it.  
Mechanical tasks: delegate them.

But be honest: sometimes "tedious" is code for "the hard part I don't want to do." If the tedious thing is actually where the thinking happens—reading carefully, considering alternatives, verifying claims—then the tedium is the point.

---

### How do I handle pressure to be faster?

Acknowledge the trade-off honestly.

"I can produce this faster if we're okay with less depth. Here's what we'd be skipping. Is speed worth more than [specific thing]?"

Sometimes it is. Sometimes the person asking realizes they actually do want the depth.

The key is making the trade-off visible rather than silently accepting lower-quality thinking.

---

## After Using the Workbook

### How do I know if I'm improving?

Some signs:
- You catch yourself before disengaging, without needing the workbook
- You can explain your reasoning better
- You notice when AI is wrong more often
- You feel more confident in your own judgment
- You're building expertise in your domain, not just outputs

---

### What if I slip back into old habits?

That's normal. Don't beat yourself up.

Return to the Implementation Tracker. Do another awareness week. Identify where you're slipping and redesign those specific workflows.

Building habits takes repetition. Occasional slips are part of the process.

---

### Should I share this framework with my team?

If it would help them, yes.

The best way is to model it yourself first. When people see you making better decisions, explaining your reasoning clearly, producing higher-quality work—they might ask how.

That's a better entry point than "here's a framework you should follow."

---

## Philosophical Questions

### Isn't some loss of expertise inevitable as AI gets better?

Maybe. But the question is: what do you want to be good at?

If you're a knowledge worker, your value comes from thinking. If you outsource that entirely, what's left?

The goal isn't to avoid AI. It's to use it in ways that develop your capabilities rather than replacing them. Even if AI can do something, there's value in you being able to do it too.

---

### What's the endgame here? Will this always be necessary?

Honestly, I don't know.

Maybe AI will become good enough that human thinking is genuinely less valuable. Maybe the people who maintain strong thinking skills will be even more valuable in contrast.

The framework is for now—for this moment where AI is powerful but not omniscient, where human judgment still matters, where the risks of cognitive offloading are real.

Whether it's always necessary? We'll find out.

---

### Isn't worrying about this just Luddism?

No. Luddism is opposing technology. This is thinking carefully about how to use it.

The framework doesn't say "don't use AI." It says "use AI in ways that preserve what makes you valuable."

That's not resistance to progress. That's engaging with it thoughtfully.


