# Framework Principles

This document explains the thinking behind the framework. Not just what to do, but why it matters.

---

## The Problem

Here's what's happening: we have incredibly powerful tools for thinking, and they might be making us worse at thinking.

Not because the tools are bad. Because we're using them in ways that bypass our own cognition instead of enhancing it.

Advait Sarkar, a researcher at Microsoft Research, calls this "the outsourcing problem." When we let AI do our reading, our analysis, our writing—when our job becomes reviewing what AI produces rather than producing things ourselves—we stop engaging with the material. We lose touch with our own thinking process. We become, as he puts it, "middle managers for our own thoughts."

This matters because thinking isn't just about producing outputs. It's how we develop judgment. It's how we build expertise. It's how we actually understand things, rather than just knowing about them.

---

## Why Three Questions?

The framework centers on three questions because there are three distinct things that can go wrong when we use AI.

### 1. We can lose contact with the material

This is the most obvious failure mode. You need to understand a document, so you ask AI to summarize it. Now you understand AI's interpretation of the document, not the document itself.

You might think: so what? The summary contains the key points.

But here's what you miss:
- The texture and nuance of the original
- Things the AI didn't think were important but you might
- The chance to form your own first impression
- The deep engagement that creates lasting understanding

When researchers study how expertise develops, they consistently find that direct engagement with material is essential. You can't shortcut to understanding by only reading summaries. The effort of engaging with difficult material is what builds comprehension.

### 2. We can lose the productive struggle

There's a concept in learning science called "desirable difficulties." Some kinds of struggle make learning better, not worse. Having to figure something out yourself, even if it takes longer, leads to deeper understanding than being told the answer.

AI removes the struggle. It gives you the answer immediately. And often that's fine—there's no learning value in struggling with a simple calculation or a formatting task.

But for tasks that matter—where you're supposed to develop judgment, form opinions, understand complex issues—the struggle is the point. When AI removes it, it removes what makes the activity valuable.

This is why Question 2 asks about "productive resistance." Is AI challenging you? Making you think harder? Or is it just executing your requests without friction?

If AI never pushes back, you never have to defend your thinking. You never have to question whether you're right. You lose the chance to improve your judgment through the process of exercising it.

### 3. We can lose awareness of our own thinking

This might be the subtlest problem.

When you're thinking through something yourself, you're aware of your reasoning process. You know why you reached the conclusions you did. You can articulate your logic.

When you're reviewing AI output, this awareness fades. You're evaluating whether something sounds right, not generating the reasoning yourself. And "sounds right" is a poor substitute for "I understand why this is right."

Sarkar's research found that people using AI often couldn't explain why they accepted or rejected particular suggestions. They just... did. Something felt right or didn't. This is thinking without metacognition—reacting without awareness.

The problem is that expertise depends on metacognition. To get better at something, you need to understand how you think about it. If AI handles the thinking and you just approve the results, that improvement doesn't happen.

---

## The Research Base

This framework isn't just a philosophy. It's grounded in research about how thinking and expertise actually develop.

### Cognitive Load Theory

This body of research shows that working memory has limits. AI can genuinely help by offloading things that would overwhelm our cognitive capacity.

But it also shows that some cognitive load is necessary for learning. When we make things too easy, learning doesn't happen. The effort of processing information is part of how we internalize it.

The framework tries to distinguish between cognitive load that helps (the struggle that builds understanding) and cognitive load that just wastes energy (formatting, remembering syntax, organizing information).

### Expertise Development

Research on expertise consistently shows that it develops through deliberate practice—engaging with challenging material in a way that stretches your current capabilities.

You can't develop expertise by reviewing outputs. You develop it by doing the work yourself, making mistakes, getting feedback, and adjusting.

This doesn't mean AI has no role. A tennis player uses a ball machine and a chess player uses analysis software. But the tool serves the practice—it doesn't replace it.

### Sensemaking and Understanding

There's a difference between knowing about something and understanding it. Knowing is having information. Understanding is being able to work with it—apply it, explain it, connect it to other things.

Understanding requires engagement. You have to think about the material, not just receive it. When AI does the thinking and you just absorb the conclusions, you might know about something without understanding it.

---

## The Three Properties of Good AI Use

Based on this research, good AI use preserves three things:

### 1. Material Engagement

You maintain direct contact with the actual source material. You read documents, not just summaries. You work with data, not just conclusions. You engage with the substance of the problem.

AI can help you organize, highlight, compare, or analyze—but it shouldn't be a wall between you and the material.

### 2. Productive Resistance

Using AI makes you think harder, not less. You're challenged to defend your ideas, consider alternatives, identify flaws in your reasoning.

This usually means prompting AI differently—asking for pushback, not validation. It means being prepared to disagree with AI and articulate why.

### 3. Metacognition

You stay aware of your own thinking process. You can explain why you made particular choices. You notice when you're accepting things without evaluation.

This usually means creating external artifacts—notes, decision logs, outlines—that make your thinking visible to yourself.

---

## When This Framework Doesn't Apply

Let's be clear about the limits.

This framework is for tasks where thinking matters. Where the goal isn't just an output, but developing understanding or exercising judgment.

There are plenty of tasks where this doesn't apply:

- **Pure execution tasks:** Formatting a document, generating boilerplate code, converting between formats. No thinking is needed; efficiency is the goal.

- **Tasks outside your development area:** If you're never going to develop expertise in something, there's no learning to protect. Get the output you need.

- **Low-stakes decisions:** Not everything needs deep thought. Use AI for the trivial stuff so you have energy for what matters.

The question is always: *Is there thinking here that I should be doing?* If not, let AI handle it. If yes, make sure you're actually doing that thinking.

---

## The Deeper Point

Underneath all of this is a simple idea: the point of thinking isn't just to produce outputs. It's to become someone who thinks well.

Every time you work through a difficult problem, you get a little better at thinking. Every time you engage deeply with material, you understand your domain more deeply. Every time you exercise judgment, your judgment improves.

When AI does these things for you, you get outputs, but you don't get better. And in knowledge work, getting better is what makes you valuable.

This isn't an argument against AI. AI is an incredible tool. But like any powerful tool, how you use it matters. Use it to extend your capabilities, not to replace them. Use it to think more, not to think less.

That's what this framework is for.

---

## Attribution

This framework is based entirely on the work of Advait Sarkar and the Microsoft Research Tools for Thought team. The core ideas—the three questions, the concept of productive resistance, the emphasis on metacognition—all come from his research and his TED talk, "How to Stop AI from Killing Your Critical Thinking."

I've organized it into an interactive format, but the thinking is his. See his work for the deeper research base.


